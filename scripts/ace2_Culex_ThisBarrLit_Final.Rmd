---
title: "Historical and Ace2 PCR results, Culex pipiens complex, Barr + Lit + This"
author: "Norah Saarman"
date: "2024-02-27"
output: pdf_document
---

R build: Geospatial 4.4.0 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(maps)
library(sp)
library(mapdata)
source("http://membres-timc.imag.fr/Olivier.Francois/POPSutilities.R")
library(fields)
library(mapplots)
```

## Import species/hybrid countsAll per site

```{r}
countsAll <- read.csv("../data/Barr1957_plusLit_plusThisStudy.txt", sep = "\t")
countsAllSp <- SpatialPoints(coords = cbind(countsAll$long,countsAll$lat))
```
Genotypes in p/q notation:
Cx. pipiens = pp
Cx. quinquefasciatus = qq


## Create a dataframe of countsAll
```{r, warning = FALSE}
# start data frame and name fields
countsAllDf <- as.data.frame(countsAll[,c(2,1,4,5,6,9,10,7,8)])
names(countsAllDf) <- c("locality","site","pp","pq","qq","latitude","longitude","year","h_index")

# name rows
rownames(countsAllDf)<- countsAllDf$site
```

## Pie charts on a map
Convert countsAll to proportions (frequency):
```{r, warning = FALSE}
freqsDf <- as.data.frame(countsAllDf[,c("pp","pq","qq")])
freqsDf <- as.matrix.data.frame(t(apply(freqsDf, 1, function(row) row / sum(row))))
```

One pie chart at a time, to check code
```{r, include=F , warning = FALSE}
for (i in 1:length(freqsDf[,1])){
  pie(freqsDf[i,],main=i,col=c("black","grey","white"),radius=.2,clockwise=TRUE,labels = NA)
}
```

Plot points on map to check data:
```{r, warning = FALSE}
# Set xpd to NA to allow for plotting in the margins
par(xpd = NA)

#create and plot coord = long, lat
coord <- as.data.frame(countsAllDf[,c("longitude","latitude")])

#plot coordinates onto map
map("usa")
map(add = T, col = "grey90", fill = TRUE)
points(coord,col="black",cex=1,pch=3)
```

Add pies to map following: "http://membres-timc.imag.fr/Olivier.Francois/Conversion.R"

```{r, warning = FALSE}
# Open PDF device
#pdf("../figs/ace2_pies_ThisBarrLit.pdf", width = 8, height = 6)

# Set xpd to NA to allow for plotting in the margins
par(xpd = NA)

# Determine plot order by descending h_index
#plot_order <- rev(order(countsAllDf$h_index))
plot_order <- rev(c(order(countsAllDf$h_index)[countsAllDf$year > 2021], order(countsAllDf$h_index)[countsAllDf$year <= 2021]))
plot_order <- c(rev(order(countsAllDf$h_index)[countsAllDf$year <= 2021]), rev(order(countsAllDf$h_index)[countsAllDf$year > 2021]))

# plot pies onto map
map("usa")
map(add = T, col = "grey90", fill = TRUE)
for (i in plot_order){
  add.pie(z = freqsDf[i,], 
          x = coord[i,1], 
          y = coord[i,2], 
          clockwise=TRUE, 
          labels = "", 
          col = c("black","grey","white"), 
          cex = 1, radius = 1 )
}
#dev.off()
```

```{r, include=T, eval=T}
# Plot with small dots for fixed sites... but doesn't look great.

# Set xpd to NA to allow for plotting in the margins
par(xpd = NA)

# Add flag for fixed sites and what type of fixed (pp or qq)
freqs_fixed <- freqsDf[, 1] == 1 | freqsDf[, 3] == 1
freqs_fixed_type <- ifelse(freqsDf[, 1] == 1, "pp",
                           ifelse(freqsDf[, 3] == 1, "qq", NA))

# Plot map with expanded margins
map("usa")
map(add = TRUE, col = "grey90", fill = TRUE)

for (i in plot_order) {
  if (freqs_fixed[i]) {
    if (freqs_fixed_type[i] == "pp") {
      # Black dot
      points(coord[i,1], coord[i,2], pch = 21, bg = "black", col = "black", cex = 1.2)
    } else if (freqs_fixed_type[i] == "qq") {
      # White dot with black border
      points(coord[i,1], coord[i,2], pch = 21, bg = "white", col = "black", cex = 1.2)
    }
  } else {
    add.pie(z = freqsDf[i,], 
          x = coord[i,1], 
          y = coord[i,2], 
          clockwise=TRUE, 
          labels = "", 
          col = c("black","grey","white"), 
          cex = 1, radius = 1 )
  }
}
```

```{r setup2, include=FALSE}
# Load libraries
library(raster)
library(terra)
library(sf)
library(dplyr)
library(maps)
library(ggplot2)
library(sp)
library(mapdata)
library(fields)
library(mapplots)
library(clue)
```

# 1. Load and Process Species Distribution Models (SDMs)

```{r load-sdms, warning = FALSE}
# Load MaxEnt SDMs
sdm_pipiens <- raster("../gis/culex_pipiens_meansuitability.nc")
sdm_quinque <- raster("../gis/culex_quinquefasciatus_meansuitability.nc")

# Threshold to binary
threshold <- 0.5
sdm_pipiens_bin <- sdm_pipiens >= threshold
sdm_quinque_bin <- sdm_quinque >= threshold
```

# 2. Convert SDMs to Polygons

```{r convert-polygons, warning = FALSE}
# Raster to terra
sdm_pipiens_v <- terra::rast(sdm_pipiens_bin)
sdm_quinque_v <- terra::rast(sdm_quinque_bin)

# Raster to polygons
poly_pipiens <- terra::as.polygons(sdm_pipiens_v, dissolve = TRUE)
poly_quinque <- terra::as.polygons(sdm_quinque_v, dissolve = TRUE)

# Terra to sf
poly_pipiens_sf <- st_as_sf(poly_pipiens)
poly_quinque_sf <- st_as_sf(poly_quinque)

# Filter to presence only
names(poly_pipiens_sf)[1] <- "presence"
names(poly_quinque_sf)[1] <- "presence"
poly_pipiens_sf <- poly_pipiens_sf %>% filter(presence == 1)
poly_quinque_sf <- poly_quinque_sf %>% filter(presence == 1)
```

# 3. Project to Albers Equal Area and Calculate Overlap

```{r project-and-overlap, warning = FALSE}
# Define CRS
aea_crs <- st_crs("+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96")

# Project
poly_pipiens_sf <- st_transform(poly_pipiens_sf, aea_crs)
poly_quinque_sf <- st_transform(poly_quinque_sf, aea_crs)

# Overlap
overlap_sf <- st_intersection(poly_pipiens_sf, poly_quinque_sf)

# Calculate areas (km²)
area_pipiens_km2 <- sum(st_area(poly_pipiens_sf)) / 1e6
area_quinque_km2 <- sum(st_area(poly_quinque_sf)) / 1e6
area_overlap_km2 <- sum(st_area(overlap_sf)) / 1e6
```

# 4. Clip to North America and Reproject to WGS84

```{r clip-and-reproject, warning = FALSE}
# US base map
us_states <- st_as_sf(map("usa", plot = FALSE, fill = TRUE))
us_states <- st_transform(us_states, crs = aea_crs)

# Clip extent
bbox_na <- st_as_sfc(st_bbox(c(xmin = -170, xmax = -50, ymin = 5, ymax = 85), crs = st_crs(4326)))
bbox_na_sf <- st_transform(bbox_na, crs = aea_crs)

# Clip
poly_pipiens_sf <- st_intersection(st_make_valid(poly_pipiens_sf), bbox_na_sf)
poly_quinque_sf <- st_intersection(st_make_valid(poly_quinque_sf), bbox_na_sf)
overlap_sf <- st_intersection(st_make_valid(overlap_sf), bbox_na_sf)

# Reproject to WGS84
poly_pipiens_ll <- st_transform(poly_pipiens_sf, 4326)
poly_quinque_ll <- st_transform(poly_quinque_sf, 4326)
overlap_ll <- st_transform(overlap_sf, 4326)
```


# 6. Merge Nearby Overlapping zones

```{r merge-nearby-overlap, warning = FALSE}
# Reproject overlap
overlap_ll_proj <- st_transform(overlap_ll, aea_crs)

# Make valid and extract polygons
overlap_valid <- st_make_valid(overlap_ll_proj)
overlap_polygons <- st_collection_extract(overlap_valid, "POLYGON")
overlap_parts <- st_cast(overlap_polygons, "POLYGON")

# Buffer outward
buffer_dist_meters <- 25000
overlap_buffered <- st_buffer(overlap_parts, dist = buffer_dist_meters)
overlap_buffered <- st_make_valid(overlap_buffered)

# Merge touching patches
overlap_combined <- st_union(overlap_buffered)
overlap_combined <- st_make_valid(overlap_combined)

# Buffer inward
overlap_combined <- st_buffer(overlap_combined, dist = -buffer_dist_meters)
overlap_combined <- st_make_valid(overlap_combined)

# Finalize
overlap_combined <- st_cast(overlap_combined, "MULTIPOLYGON")
overlap_combined <- st_transform(overlap_combined, 4326)

#pdf("../figs/overlap_SDM_ThisBarrLit.pdf", width = 8, height = 6)
par(xpd = NA)
map("usa")
map(add = TRUE, col = "grey90", fill = TRUE)

plot(st_geometry(poly_pipiens_ll), col = rgb(0, 0, 1, 0.3), border = NA, add = TRUE)
plot(st_geometry(poly_quinque_ll), col = rgb(0, 1, 0, 0.3), border = NA, add = TRUE)
plot(st_geometry(overlap_combined), col = adjustcolor("#fc8d59", alpha.f = 0.9), border = NA, add = TRUE)

map("state", add = TRUE, col = "black", lwd = 0.5)

# Add sampling points, but looks messy:
# points(coord,col="black",cex=1,pch=3)

#dev.off()
```

Predicted level of overlapping suitable habitat?
```{r, warning=FALSE}
# ---------------------------------------------
# Quantify predicted overlap around each sample point
# ---------------------------------------------

# Step 1: Make sample points an sf object
samples_sf <- st_as_sf(countsAllDf, coords = c("longitude", "latitude"), crs = 4326)

# Step 2: Reproject sample points to Albers Equal Area CRS
samples_sf <- st_transform(samples_sf, crs = aea_crs)

# Step 3: Buffer each point by 30 km (30,000 meters)
sample_buffers <- st_buffer(samples_sf, dist = 30000)

# Step 4: Prepare overlap_combined layer in same CRS
overlap_combined_proj <- st_transform(overlap_combined, crs = aea_crs)

# Step 5: Calculate proportion of buffer area that overlaps
predicted_overlap_prop <- sapply(1:nrow(sample_buffers), function(i) {
  buf <- sample_buffers[i,]
  intersection <- st_intersection(buf, overlap_combined_proj)
  
  if (nrow(intersection) == 0) {
    # No overlap
    overlap_area <- 0
  } else {
    # Sum all overlapping parts
    overlap_area <- sum(st_area(intersection))
  }
  
  buffer_area <- st_area(buf)
  
  # Return proportion
  as.numeric(overlap_area) / as.numeric(buffer_area)
})

# Step 6: Add predicted overlap to countsAllDf
countsAllDf$predicted_overlap <- predicted_overlap_prop
```
# Predicted H-index  

Now, add directionality with 0 = quinq, 1 = pip, to estimate "predicted_h_index"  

Predicted h_index based on **Current** SDM habitat MaxEnt models also included, although I wonder about the logic of this, since climate HAS changed?  

```{r, warning = FALSE}
# ---------------------------------------------
# New: Predict directional hybrid index from habitat around each sampling site
# ---------------------------------------------

# Step 1: Prepare the pipiens-only and quinque-only polygons
# (We already have poly_pipiens_ll and poly_quinque_ll, but need to transform)
poly_pipiens_proj <- st_transform(poly_pipiens_ll, crs = aea_crs)
poly_quinque_proj <- st_transform(poly_quinque_ll, crs = aea_crs)
overlap_combined_proj <- st_transform(overlap_combined, crs = aea_crs)  # already done above

# Step 2: Create pip-only and quinque-only polygons (remove overlap area)
pip_only <- st_difference(poly_pipiens_proj, overlap_combined_proj)
quinque_only <- st_difference(poly_quinque_proj, overlap_combined_proj)

# Step 3: Calculate areas for each sample buffer
library(units)  # make sure units package is loaded

predicted_h_index <- sapply(1:nrow(sample_buffers), function(i) {
  buf <- sample_buffers[i, ]
  
  pip_intersect <- st_intersection(buf, pip_only)
  quinque_intersect <- st_intersection(buf, quinque_only)
  overlap_intersect <- st_intersection(buf, overlap_combined_proj)
  
  pip_area <- if (nrow(pip_intersect) == 0) units::set_units(0, "m^2") else sum(st_area(pip_intersect))
  quinque_area <- if (nrow(quinque_intersect) == 0) units::set_units(0, "m^2") else sum(st_area(quinque_intersect))
  overlap_area <- if (nrow(overlap_intersect) == 0) units::set_units(0, "m^2") else sum(st_area(overlap_intersect))
  
  total_area <- pip_area + quinque_area + overlap_area
  
  if (as.numeric(total_area) == 0) {
    return(NA)  # no habitat found
  } else {
    pred_h <- (pip_area + 0.5 * overlap_area) / total_area
    return(as.numeric(pred_h))  # strip units at the end
  }
})
# Step 4: Add predicted_h_index to countsAllDf
countsAllDf$predicted_h_index <- predicted_h_index

# Step 5: Quick check and save
(summary_table <- countsAllDf[, c("site", "latitude", "longitude", "h_index", "predicted_overlap", "predicted_h_index")])

# Save as CSV
# write.csv(summary_table, file = "../data/summary_hindex_prediction.csv", row.names = FALSE)
```
```{r, include=F, eval=F}
#Aside: bookmark on colors i like
zach_colors <- c(
  "#1f78b4",  # Anna – dark blue
  "#33a02c",  # Ricei – forest green
  "#6a3d9a",  # Idas – dark purple
  "#d73027",  # Melissa – red
  "#ffb400",  # Warner – mustard
  "#1dd5c8",  # Alpine – cyan
  "#fb9a99"   # Jackson – pink
)
```

# Plot h_index versus predicted_h_index, latitude, etc...

## By Zone: H-index versus Predicted H-index and Latitude
```{r, warning=FALSE}
library(ggplot2)
library(dplyr)
library(patchwork)

# Define hybrid zones:

countsAllDf$zone <- NULL
countsAllDf$zone <- case_when(
  grepl("CA|OR|WA", countsAllDf$site) ~ "West Coast",
  grepl("NJ|MD|MA|DE|CT|NY|VA|FL|QC|DC|TN|GA|NC", countsAllDf$site) ~ "East Coast",
  grepl("TX|LA|IL|LA|MN|ON|KS|MO|AR|AL|MS", countsAllDf$site) ~ "Central",
  grepl("UT|CO|AZ", countsAllDf$site) ~ "Mtn/Southwest"
)

# Control order by making it a factor
countsAllDf$zone <- factor(countsAllDf$zone, levels = c("West Coast", "Mtn/Southwest", "Central", "East Coast"))

# Define zone color palette
zone_colors <- c(
   "Mtn/Southwest" = "#d73027", 
   "Central" =   "#6a3d9a", 
   "West Coast" = "#e6b800", 
   "East Coast" ="#1f78b4"
)

# Create shared color scale
zone_scale <- scale_color_manual(values = zone_colors, name = "Zone:")

# Shared theme for both plots
shared_theme <- theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    legend.position = "bottom",  # <-- Legend at bottom
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 8),
    plot.margin = margin(10, 10, 10, 10)
  )

# ---------------------------------------
# H-index vs Predicted H-index
# ---------------------------------

r2_pred <- countsAllDf %>%
  group_by(zone) %>%
  summarise(r2 = summary(lm(predicted_h_index ~ h_index))$r.squared)

p2 <- ggplot(countsAllDf, aes(x = h_index, y = predicted_h_index, color = zone)) +
  geom_point(size = 3, alpha = 0.5, shape = 16) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 1.2) +
  geom_text(data = r2_pred, aes(x = 0.05, y = 0.95 - as.numeric(zone) * 0.05, 
                                label = paste0("R² = ", round(r2, 2)), color = zone),
            hjust = 0, size = 3.5, inherit.aes = FALSE) +
  theme_minimal() +
  labs(x = "H-index", y = "Predicted H-index (from SDM)", title = "Predicted H-index", color = "Zone:") +
  xlim(0, 1) +
  ylim(0, 1) +
  scale_color_manual(values = zone_colors)
  guides(color = guide_legend(override.aes = list(alpha = 1, shape = NA, linetype = 1)))


# ---------------------------------------
#  H-index vs Latitude
# ---------------------------------------
r2_lat <- countsAllDf %>%
  group_by(zone) %>%
  summarise(r2 = summary(lm(latitude ~ h_index))$r.squared)

p1 <- ggplot(countsAllDf, aes(x = h_index, y = latitude, color = zone)) +
  geom_point(size = 3, alpha = 0.5, shape = 16) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 1.2) +
  geom_text(data = r2_lat, aes(x = 0.05, y = max(countsAllDf$latitude, na.rm = TRUE) - as.numeric(zone) * 1.5, 
                               label = paste0("R² = ", round(r2, 2)), color = zone),
            hjust = 0, size = 3.5, inherit.aes = FALSE) +
  theme_minimal() +
  labs(x = "H-index", y = "Latitude", title = "Latitude", color = "Zone:") +
  xlim(0, 1) +
  scale_color_manual(values = zone_colors)
  guides(color = guide_legend(override.aes = list(alpha = 1, shape = NA, linetype = 1)))

# ---------------------------------------
# Combine plots with unified legend at bottom
# ---------------------------------------

# Define the plot object
final_plot  <- (p2 | p1) + plot_layout(guides = 'collect') & theme(legend.position = "bottom")

  final_plot
# Save as PDF with specific width and height (in inches)
#ggsave("../figs/h_index_lm_all_by_zone.pdf", plot = final_plot, width = 7, height = 4, units = "in")
```
## By Year: H-index vs Predicted H-index and Latitude

```{r, warning = FALSE}
library(ggplot2)
library(dplyr)
library(patchwork)

countsAllDf <- countsAllDf %>%
  mutate(time_frame = case_when(
    year >= 1939 & year <= 1961 ~ "1940-1960",
    year >= 1989 & year <= 2019 ~ "1990-2019",
    year >= 2020 & year <= 2024 ~ "2020-2024",
    TRUE ~ "Other"
  ))

# Optional: Make time_frame a factor to control order
countsAllDf$time_frame <- factor(countsAllDf$time_frame, 
                                 levels = c("1940-1960", "1990-2019", "2020-2024"))

time_frame_colors <- c("1940-1960" = "#A7A9D1",  # muted lavender/blue
                       "1990-2019" = "#78A9CF",  # moderate blue
                       "2020-2024" = "#80CBC4")  # aqua-green, clearly distinct
 
time_frame_scale <- scale_color_manual(values = time_frame_colors, name = "Time Frame:")

# Shared theme
shared_theme <- theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    legend.position = "bottom",
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 8),
    plot.margin = margin(10, 10, 10, 10)
  )

# ---------------------------------------
# H-index vs Predicted H-index
# ---------------------------------------

r2_pred <- countsAllDf %>%
  group_by(time_frame) %>%
  summarise(r2 = summary(lm(predicted_h_index ~ h_index))$r.squared)

p2 <- ggplot(countsAllDf, aes(x = h_index, y = predicted_h_index, color = time_frame)) +
  geom_point(size = 3, alpha = 0.5, shape = 16) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 1.2) +
  geom_text(data = r2_pred, aes(x = 0.05, y = 0.95 - as.numeric(time_frame) * 0.05, 
                                label = paste0("R² = ", round(r2, 2)), color = time_frame),
            hjust = 0, size = 3.5, inherit.aes = FALSE) +
  shared_theme +
  labs(x = "H-index", y = "Predicted H-index (from SDM)", title = "Predicted H-index", color = "Time Frame:") +
  xlim(0, 1) +
  ylim(0, 1) +
  time_frame_scale


# ---------------------------------------
#  H-index vs Latitude
# ---------------------------------------

r2_lat <- countsAllDf %>%
  group_by(time_frame) %>%
  summarise(r2 = summary(lm(latitude ~ h_index))$r.squared)

p1 <- ggplot(countsAllDf, aes(x = h_index, y = latitude, color = time_frame)) +
  geom_point(size = 3, alpha = 0.5, shape = 16) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 1.2) +
  geom_text(data = r2_lat, aes(x = 0.05, y = max(countsAllDf$latitude, na.rm = TRUE) - as.numeric(time_frame) * 1.5, 
                               label = paste0("R² = ", round(r2, 2)), color = time_frame),
            hjust = 0, size = 3.5, inherit.aes = FALSE) +
  shared_theme +
  labs(x = "H-index", y = "Latitude", title = "Latitude", color = "Time Frame:") +
  xlim(0, 1) +
  time_frame_scale


# ---------------------------------------
# Combine plots with unified legend at bottom
# ---------------------------------------

# Define the plot object
final_plot  <- (p2 | p1) + plot_layout(guides = 'collect') & theme(legend.position = "bottom")

final_plot
# Save as PDF with specific width and height (in inches)
#ggsave("../figs/h_index_lm_all_by_time.pdf", plot = final_plot, width = 7, height = 4, units = "in")
```

# ANCOVA (Analysis of Covariance)

This allows you to test:

Whether slopes differ significantly by zone vs. time.

Whether overall fit is better when grouping by zone vs. by time.

You can compare models using AIC or adjusted R².

```{r, warning = FALSE}
# Model 1: Zone as factor
mod_zone <- lm(latitude ~ h_index * zone, data = countsAllDf)

# Model 2: Time Frame as factor
mod_time <- lm(latitude ~ h_index * time_frame, data = countsAllDf)

# Compare model fits
AIC(mod_zone, mod_time)
summary(mod_zone)
summary(mod_time)
```

Repeat with SDM predicted H-index
```{r, warning = FALSE}
# Model with zone
mod_pred_zone <- lm(predicted_h_index ~ h_index * zone, data = countsAllDf)
summary(mod_pred_zone)

# Model with time frame
mod_pred_time <- lm(predicted_h_index ~ h_index * time_frame, data = countsAllDf)
summary(mod_pred_time)

# Compare model fits
AIC(mod_pred_zone, mod_pred_time)
summary(mod_pred_zone)
summary(mod_pred_time)
```